=========================================================================
Feb 10 2026                                                      Entry  1

# Researched how to write a CNN from scratch
   - Resources:
   - https://github.com/euske/nn1/
   - https://github.com/usamahz/cnn/
   - https://www.ibm.com/think/topics/convolutional-neural-networks

# Convolutional Neural Network:
   - Form of Neural Network
   - Uses three-dimensional data for image classification and
     object recognition tasks
   - Computationally expensive-- requires GPU for training
   - Three main types of layers:
      - Convolutional layer
      - Pooling layer
      - Fully-Connected layer

# Convolutional Layer:
   - Input (in our case, a color image)
      - 3 dimensions corresponding to RGB
   - Feature detector (AKA Kernel/Filter)
      - 2D array of weights
      - Represents part of the image
      - Filter size typically = 3x3 matrix
      - Applied to an area of the image
      - Dot product is calculated between input pixels and 
        filter and fed into an output away
      - Filter shifts by a stride, repeating until kernel
        sweeps across entire input
   - Feature Map
      - Final output from series of dot products from input and
        filter

# Pooling Layer:
   - Also known as downsampling
   - Dimensionality reduction, reducing number of input parameters
   - Also sweeps a filter across entire input, but the filter has 
     no weights
   - Applies aggregation function to values within field
   - Two types:
      - Max (selects pixel with max value in the filter)
      - Average (selects average value in receptive field to send
        to output array)
   - Info is lost but pooling layers reduce complexity, improve 
     efficiency, and reduce overfitting

# Fully-Connected Layer:
   - Each node in output layer directly connects to a node in the
     previous layer
   - Performs classification based on features extracted through
     previous layers
   - Convolutional/pooling tend to use ReLU activation function,
     while FC tends to use softmax to classify inputs
     appropriately, with a confidence score 0-1

=========================================================================
Feb 15 2026                                                      Entry  2

# Installed Debian on desktop PC for the purpose of compiling and
  running code while also being able to write it from MAC
   - Both POSIX compliant
   - This took longer than it should have because I was trying
     to install from a corrupted USB

# Why Debian?
   - Minimal Linux Distro
      - Very little bloatware
      - Runs fast
      - Also considered Arch for these reasons 
   - Stability
      - Debian is known for its stable "release when ready"
        model
      - This is where Debian edges out Arch
   - Familiarity with APT package manager
      - I've used Ubuntu, Mint, and Kali linux in the past
      - All based on Debian and use the same package
        manager (apt)

=======================================================================
Feb 19 2026                                                    Entry  3

# Started work on the "control cnn"
   - Written in C
   - Writing a more basic neural network before adding cnn logic
   - Resources:
      - https://github.com/SebLague/Neural-Network-Experiments
   - Progress:
      - layer struct & supporting functions
      - build system (make)
=======================================================================
Feb 20 2026						       Entry  4

# Wrote Cost functions & derivatives
   - Mean Squared Error
   - Cross Entropy
   - enum cost_type to determine which cost function a network
     uses

# Started writing struct network
   - Right now it's really a list of layers
=======================================================================
